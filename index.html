<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.jsdelivr.net/npm/protobufjs@7.X.X/dist/protobuf.min.js"></script>
    <title>Mockminds WebSocket Client Example</title>
    <style>
        body {
            background-color: #000;
            color: #fff;
            font-family: 'Courier New', monospace;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
        }
        h1, h3 {
            text-align: center;
            font-weight: normal;
        }
        button {
            border: none;
            padding: 10px 20px;
            margin: 10px;
            font-family: 'Courier New', monospace;
            font-size: 16px;
            cursor: pointer;
            color: #fff;
        }
        #startAudioBtn {
            background-color: #008000;
        }
        #stopAudioBtn {
            background-color: #ff0000;
            display: none;
        }
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        #progressText {
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <h1>Mockminds AI call</h1>
    <h3><div id="progressText">Loading, wait...</div></h3>
    <div>
        <button id="startAudioBtn">Start Call</button>
        <button id="stopAudioBtn">End Call</button>
    </div>
    <script>
      // [1] Use MediaRecorder with a timeSlice to capture short,
      // continuous audio chunks and send them via WebSocket.
      let ws = null;
      let mediaRecorder = null;
      let startBtn = document.getElementById('startAudioBtn');
      let stopBtn = document.getElementById('stopAudioBtn');
      let statusDiv = document.getElementById('status');

      // Replace with your running server's WebSocket URL:
      // Example for Render: wss://<your-app-name>.onrender.com
      const WS_URL = "wss://pipecat-eg.onrender.com";

      startBtn.addEventListener('click', async () => {
        try {
          startBtn.disabled = true;
          stopBtn.disabled = false;
          statusDiv.textContent = "Status: Initializing WebSocket and audio...";

          // Initialize WebSocket
          ws = new WebSocket(WS_URL);
          ws.binaryType = "arraybuffer";

          ws.onopen = async () => {
            statusDiv.textContent = "Status: WebSocket connection opened.";

            // Request microphone access
            const stream = await navigator.mediaDevices.getUserMedia({
              audio: {
                sampleRate: 16000,
                channelCount: 1,
                autoGainControl: true,
                echoCancellation: true,
                noiseSuppression: true,
              },
            });

            // Use MediaRecorder with Opus codec
            mediaRecorder = new MediaRecorder(stream, {
              mimeType: "audio/webm; codecs=opus",
            });

            // Send audio chunks continuously
            mediaRecorder.ondataavailable = (event) => {
              // Only send if data is non-empty
              if (event.data && event.data.size > 0) {
                event.data.arrayBuffer().then((arrayBuffer) => {
                  if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(arrayBuffer);
                  }
                });
              }
            };

            // Emit audio chunks every 250ms (adjust as needed for low/high latency)
            mediaRecorder.start(250);
            statusDiv.textContent = "Status: Recording audio and sending to server.";
          };

          ws.onmessage = (event) => {
            // [2] Play incoming audio data from the server
            decodeAndPlayAudio(event.data);
          };

          ws.onerror = (err) => {
            console.error("WebSocket error:", err);
            statusDiv.textContent = "Status: WebSocket error occurred.";
          };

          ws.onclose = () => {
            statusDiv.textContent = "Status: WebSocket connection closed.";
            startBtn.disabled = false;
            stopBtn.disabled = true;
          };
        } catch (err) {
          console.error("Error during start:", err);
          statusDiv.textContent = "Status: Error initializing.";
          startBtn.disabled = false;
        }
      });

      stopBtn.addEventListener("click", () => {
        stopAudioStreaming(true);
      });

      function stopAudioStreaming(closeWebSocket) {
        if (mediaRecorder && mediaRecorder.state !== "inactive") {
          mediaRecorder.stop();
        }
        if (closeWebSocket && ws) {
          ws.close();
          ws = null;
        }
        startBtn.disabled = false;
        stopBtn.disabled = true;
        statusDiv.textContent = "Status: Streaming stopped.";
      }

      async function decodeAndPlayAudio(arrayBuffer) {
        try {
          const audioContext = new (window.AudioContext || window.webkitAudioContext)();
          const decodedData = await audioContext.decodeAudioData(arrayBuffer);
          const source = audioContext.createBufferSource();
          source.buffer = decodedData;
          source.connect(audioContext.destination);
          source.start();
        } catch (error) {
          console.error("Audio decoding error:", error);
        }
      }
    </script>
  </body>
</html>
